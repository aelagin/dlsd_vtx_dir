{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables\n",
    "maxT = 150\n",
    "maxLambda = 720 # there is also min lamda at around 350nm, one can do a better normalization\n",
    "PAD_VALUE = -1\n",
    "NEvts = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes input array and creates a list of arrays, where each array in the list is a 1D event\n",
    "# each 1D event is [hit1_theta, hit1_phi, hit1_time, hit1_color,   hit2_theta, hit2_phi, hit2_time, hit2_color etc]\n",
    "# takes color only if take_color=1\n",
    "def create_images(data, take_color=1):\n",
    "    #print(data[:,0])\n",
    "    images = []\n",
    "    for i_event in range(0,NEvts) :\n",
    "        X = data[np.where(data[:,0]==i_event)] #take all rows where 1st colummn correspond to current event\n",
    "        X = np.delete(X,0,1) #delete column with event number\n",
    "        \n",
    "        if take_color==0 :\n",
    "            X = np.delete(X,3,1) #delete column with color\n",
    "        \n",
    "        n_phot = X.shape[0]\n",
    "        \n",
    "        #keeping only a pre-set percentage of photons (mimic photo-coverage)\n",
    "        ind = np.arange(n_phot)\n",
    "        np.random.shuffle(ind)\n",
    "        n_phot = int(np.ceil(n_phot*0.65)) # 65% coverage\n",
    "        X = X[ ind[:n_phot], : ]\n",
    "        \n",
    "#         # The commented section below is only needed for time semearing\n",
    "#         # can be left commented when working with true time\n",
    "        \n",
    "#         ##time_jitter = np.random.normal(0,0.4899,n_phot)\n",
    "#         ##time_jitter = np.random.normal(0,0.7433,n_phot)\n",
    "#         #time_jitter = np.random.normal(0,0.229129,n_phot)\n",
    "#         #np.random.shuffle(time_jitter)\n",
    "#         #time_jitter = time_jitter.reshape(n_phot,1)\n",
    "#         th_ph = np.zeros((n_phot,2))\n",
    "#         if take_color==1 :\n",
    "#             color = np.zeros((n_phot,1))\n",
    "#         #time_jitter = np.hstack((th_ph,time_jitter))\n",
    "#         #X = X - time_jitter\n",
    "        \n",
    "#         t_min = np.ones((n_phot,1))*min(X[:,2])\n",
    "#         t_min = np.hstack((th_ph,t_min))\n",
    "#         if take_color==1 :\n",
    "#             t_min = np.hstack((t_min,color))\n",
    "#         X = X - t_min\n",
    "             \n",
    "        X=X[np.argsort(X[:,2])]  #order hits by time within an event\n",
    "     \n",
    "        \n",
    "        X[:,0] /= np.pi        #normalizing theta\n",
    "        X[:,1] /= (2*np.pi)    #normalizing phi\n",
    "        X[:,2] /= maxT         #normalizing time (relative to the first hit)\n",
    "        if take_color==1 :\n",
    "            X[:,3] /= maxLambda       #normalizing color\n",
    "                                # there is also min lamda at around 350nm, one can do a better normalization\n",
    "        \n",
    "        X = X.reshape(X.shape[0]*X.shape[1]) #reshape into 1D array\n",
    "\n",
    "        images.append(X)\n",
    "        \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def process_a_folder(input_dir, take_color, out_dir, fn) :\n",
    "    x1=os.listdir(input_dir)\n",
    "    x1.sort()\n",
    "    print(x1)\n",
    "    print(len(x1))\n",
    "    for idx in range (0,len(x1)) :\n",
    "        print(idx)\n",
    "        print(x1[idx])\n",
    "        #print(input_dir)\n",
    "        print(os.path.join(input_dir, x1[idx]))\n",
    "        batch_data1 = np.load(os.path.join(input_dir, x1[idx]))\n",
    "        data1 = create_images(batch_data1['evt_theta_phi_time'],take_color)\n",
    "        vtx1 = batch_data1['vtx_xyz']\n",
    "        dir1 = batch_data1['dir_xyz']\n",
    "                \n",
    "        #longest_row = max(data1,key=len) #find longest row in data\n",
    "        #print(len(longest_row))\n",
    "        Lmax = 6300 #len(longest_row) #lenght of the longest row - this is needed for padding\n",
    "        if take_color==1 :\n",
    "            Lmax = 8400\n",
    "        \n",
    "        batch_x1 = pad_sequences(data1, maxlen=Lmax, dtype='float64', padding='post', truncating='post', value=PAD_VALUE)\n",
    "        \n",
    "        out_file = 'f_batch_' + str(int(fn)+idx) + '.npz'\n",
    "        np.savez(os.path.join(out_dir, out_file), x=batch_x1, y_vtx=vtx1, y_dir=dir1)\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import Sequence\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# def process_a_folder(input_dir, take_color, out_dir, fn) :\n",
    "#     x1=os.listdir(input_dir)\n",
    "#     x1.sort()\n",
    "#     print(x1)\n",
    "#     print(len(x1))\n",
    "#     for idx in range (0,len(x1)) :\n",
    "#         print(idx)\n",
    "#         print(x1[idx])\n",
    "#         #print(input_dir)\n",
    "#         print(os.path.join(input_dir, x1[idx]))\n",
    "#         batch_data1 = np.load(os.path.join(input_dir, x1[idx]))\n",
    "#         data1 = create_images(batch_data1['evt_theta_phi_time'],take_color)\n",
    "#         vtx1 = batch_data1['vtx_xyz']\n",
    "#         dir1 = batch_data1['dir_xyz']\n",
    "                \n",
    "#         #longest_row = max(data1,key=len) #find longest row in data\n",
    "#         #print(len(longest_row))\n",
    "#         Lmax = 6300 #len(longest_row) #lenght of the longest row - this is needed for padding\n",
    "        \n",
    "#         batch_x1 = pad_sequences(data1, maxlen=Lmax, dtype='float64', padding='post', truncating='post', value=PAD_VALUE)\n",
    "#         batch_y1 = np.hstack((vtx1,dir1))\n",
    "        \n",
    "#         #the following is only needed for shuffling, not clear if that's needed for vertexing\n",
    "#         batch = np.concatenate((batch_x1, batch_y1), axis=1)\n",
    "#         batch_x1, batch_y1 = [], []\n",
    "#         np.random.shuffle(batch)\n",
    "#         batch_y1 = batch[:,-6:]\n",
    "#         batch_y1 = np.delete(batch_y1, np.s_[-3:],1) ### for the time being deleting directionality info\n",
    "        \n",
    "#         batch_x1 = np.delete(batch, np.s_[-6:],1)\n",
    "#         ###  end of the shuffling segment\n",
    "        \n",
    "#         print('batch_x1.shape = ',batch_x1.shape, 'batch_y1.shape = ',batch_y1.shape)\n",
    "#         #print(batch_x)\n",
    "#         #print(batch_y)\n",
    "#         print('=====')\n",
    "#         print('')\n",
    "#         batch = []\n",
    "     \n",
    "        \n",
    "#         out_file = 'f_batch_' + str(int(fn)+idx+1) + '.npz'\n",
    "#         np.savez(os.path.join(out_dir, out_file), x=batch_x1, y=batch_y1)\n",
    "        \n",
    "#     return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_1.npz', 'photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_2.npz', 'photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_3.npz', 'photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_4.npz', 'photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_5.npz', 'photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_6.npz', 'photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_7.npz', 'photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_8.npz', 'photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_9.npz']\n",
      "9\n",
      "0\n",
      "photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_1.npz\n",
      "/data/Elagin/data_vtx_dir_1el_test/photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_1.npz\n",
      "1\n",
      "photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_2.npz\n",
      "/data/Elagin/data_vtx_dir_1el_test/photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_2.npz\n",
      "2\n",
      "photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_3.npz\n",
      "/data/Elagin/data_vtx_dir_1el_test/photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_3.npz\n",
      "3\n",
      "photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_4.npz\n",
      "/data/Elagin/data_vtx_dir_1el_test/photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_4.npz\n",
      "4\n",
      "photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_5.npz\n",
      "/data/Elagin/data_vtx_dir_1el_test/photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_5.npz\n",
      "5\n",
      "photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_6.npz\n",
      "/data/Elagin/data_vtx_dir_1el_test/photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_6.npz\n",
      "6\n",
      "photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_7.npz\n",
      "/data/Elagin/data_vtx_dir_1el_test/photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_7.npz\n",
      "7\n",
      "photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_8.npz\n",
      "/data/Elagin/data_vtx_dir_1el_test/photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_8.npz\n",
      "8\n",
      "photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_9.npz\n",
      "/data/Elagin/data_vtx_dir_1el_test/photon_data_with_vtx_dir_xyz_allLight_maxTall_1el_2p529MeV_dVrndVtx_3p0mSphere_rndDir_1k_9.npz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#process_a_folder('/data/Elagin/vtx_dir_1el_16dd/', 1, '/data/Elagin/vtx_dir_1el_color_norm',1600)\n",
    "process_a_folder('/data/Elagin/data_vtx_dir_1el_test/', 0, '/data/Elagin/data_vtx_dir_1el_test_norm',1)\n",
    "#process_a_folder('/data/Elagin/sig_test_maxT52_che', '/data/Elagin/bkg_test_maxT52_che', 0, '/data/Elagin/test_maxT52_che')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_batch_1.npz  f_batch_3.npz  f_batch_5.npz  f_batch_7.npz  f_batch_9.npz\n",
      "f_batch_2.npz  f_batch_4.npz  f_batch_6.npz  f_batch_8.npz\n"
     ]
    }
   ],
   "source": [
    "!ls /data/Elagin/data_vtx_dir_1el_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = np.load('/data/Elagin/photon_data_with_vtx_dir_allLight_maxT37p0ns_1el_2p529MeV_dVrndVtx_0p5mSphere_rndDir_1k_1.npz')\n",
    "#print(batch['evt_theta_phi_time'])\n",
    "print(batch['vtx_theta_phi_r'])\n",
    "print(batch['dir_theta_phi'])\n",
    "\n",
    "print(np.hstack((batch['vtx_theta_phi_r'],batch['dir_theta_phi'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir1 = '/data/Elagin/sig_test_true_time_maxT37/'\n",
    "x_list = os.listdir(dir1)\n",
    "x_list.sort() #alphanumerical sorting\n",
    "print(x_list[0])\n",
    "batch_data1 = np.load(os.path.join(dir1,x_list[0]))\n",
    "data1 = create_images(batch_data1['evt_theta_phi_time'],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data1[0]))\n",
    "print(data1[0])\n",
    "\n",
    "longest_row = max(data1,key=len) #find longest row in data\n",
    "print(len(longest_row))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
